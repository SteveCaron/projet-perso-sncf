{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API SNCF: Les retards de train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Auteur :__ \n",
    "\n",
    "Steve Caron\n",
    "\n",
    "__Présentation :__ \n",
    "\n",
    "Ce script permet de requêter les informations sur les arrivées des trains en gare pour la journée d'hier. \n",
    "\n",
    "Il retourne les réponses des requêtes dans deux répertoires:\n",
    "\n",
    "* data/arrivees/ : répertoire contenant les informations sur les arrivées en gare\n",
    "\n",
    "* data/perturbations/ : répertoire contenant les informations sur les perturabations observées sur les arrivées en gare\n",
    "\n",
    "\n",
    "__Inputs :__ \n",
    "\n",
    "Un fichier data/top{n}gare.json contenant les informations permettant de faire les requêtes pour chaques gares. Les enregistrements sont classés en fonction de la fréquentation des gares.\n",
    "\n",
    "__Params :__\n",
    "\n",
    "* CLEF_API : nom sous lequel est enregistrer la cle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "from dataclasses import dataclass,asdict\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,text\n",
    "from sqlalchemy.types import *\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEF_API = \"API_KEY\"\n",
    "DB_PORT = 3306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_log_file_name = 'db.log'\n",
    "db_handler_log_level = logging.DEBUG\n",
    "db_logger_log_level = logging.DEBUG\n",
    "\n",
    "db_handler = logging.FileHandler(db_log_file_name)\n",
    "db_handler.setLevel(db_handler_log_level)\n",
    "\n",
    "db_logger = logging.getLogger('sqlalchemy')\n",
    "db_logger.addHandler(db_handler)\n",
    "db_logger.setLevel(db_logger_log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_en_string(dt):\n",
    "    '''Cette fonction convertit un datetime en chaîne de caractères'''\n",
    "    if str is None:\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strftime(dt,'%Y%m%dT%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_en_datetime(str):\n",
    "    '''Cette fonction convertit une chaîne de caractères en datetime'''\n",
    "    if str is None:\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strptime(str,\"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_json(data,nom_fichier):\n",
    "    '''Cette fonction permet d'enregistrer un fichier JSON'''\n",
    "    with open(nom_fichier, \"w\") as fc:\n",
    "        json.dump(data, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(data,nom_fichier):\n",
    "    '''Cette fonction permet d'enregistrer un fichier CSV'''\n",
    "    with open(nom_fichier,\"w\", newline='', encoding='utf-8')as fc:\n",
    "        writer = csv.DictWriter(fc,fieldnames=data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requete_api(code_gare,code_reseau,date,nb_gare):\n",
    "    '''Cette fonction effectue une requête API pour collecter la liste des arrivées pour une gare spécifique sur un réseau spécifique '''\n",
    "\n",
    "    base_url = \"https://api.sncf.com/v1/coverage/sncf\"\n",
    "    #Requete sans le filtre sur les trains\n",
    "    requete = f\"{base_url}/stop_areas/{code_gare}/networks/{code_reseau}/arrivals?from_datetime={date}&count={nb_gare}\"\n",
    "    reponse = requests.get(requete, auth=(api_key,\"\"))\n",
    "    reponse_json = reponse.json()\n",
    "    \n",
    "    return reponse_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verification_dates(reponse_API,code_gare,code_reseau,date_requete,date_max:str):\n",
    "    '''Cette fonction permet de vérifier si toutes les arrivées comprises dans une réponse API sont avant la date max\n",
    "    Si c'est le cas la fonction retourne la réponse API initiale et la date de la dernière arrivée de la réponse initiale\n",
    "    Si ce n'est pas le cas, elle refait un appel API en faisant une requete comprennant uniquement les dates antérieurs à la date max\n",
    "    La fonction retourne alors la nouvelle réponse API et la date de la dernière arrivée comprise dans la réponse initiale'''\n",
    "    datetime_max = convertir_en_datetime(date_max)\n",
    "    arrivees_reponse=reponse_API[\"arrivals\"]\n",
    "    #Gestion du cas ou la requete ne revoie pas d'arrivée\n",
    "    if len(arrivees_reponse) == 0:\n",
    "        #On retourne des liste vide et un datetime qui sera forcement supérieur à la date max\n",
    "        return [],[],datetime.datetime(9999,1,1,12,12,00)\n",
    "    datetime_derniere_requete = convertir_en_datetime(arrivees_reponse[-1][\"stop_date_time\"][\"arrival_date_time\"])\n",
    "    if datetime_derniere_requete > datetime_max:\n",
    "        for compteur,arrivee in enumerate(arrivees_reponse):\n",
    "            arrivee_datetime = convertir_en_datetime(arrivee[\"stop_date_time\"][\"arrival_date_time\"])\n",
    "            if arrivee_datetime > datetime_max:\n",
    "                reponse = requete_api(code_gare,code_reseau,date_requete,compteur)\n",
    "                return reponse[\"arrivals\"],reponse[\"disruptions\"], datetime_derniere_requete\n",
    "    else:\n",
    "        return arrivees_reponse,reponse_API[\"disruptions\"], datetime_derniere_requete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requete_entre_dates(code_gare,code_reseau,date_min,date_max,liste_arrivee,liste_perturbation,compteur_requete):\n",
    "    '''Cette fonction permet de faire des requêtes pour récupérer des données sur tous les enregistrements de la journée.\n",
    "    Elle sépare en deux listes les informations concernant les départs et les informations concernant les arrivées'''\n",
    "\n",
    "    date_requete = date_min\n",
    "\n",
    "    while date_requete < date_max:\n",
    "        # Requete api\n",
    "        reponse_api = requete_api(code_gare,code_reseau,date_requete,10)\n",
    "        compteur_requete += 1\n",
    "        arrivees,perturbations,date_derniere_requete = verification_dates(reponse_api,code_gare,code_reseau,date_requete,date_max)\n",
    "        # Ajoute chaque arrivées de la requete à la liste\n",
    "        [liste_arrivee.append(arrivee) for arrivee in arrivees]\n",
    "        # Ajoute chaque perturbations de la requete à la liste\n",
    "        [liste_perturbation.append(perturbation)  for perturbation in perturbations]\n",
    "        \n",
    "        date_requete = convertir_en_string(date_derniere_requete + datetime.timedelta(seconds=1))\n",
    "        \n",
    "    return liste_arrivee,liste_perturbation,compteur_requete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liste_id(nom_fichier):\n",
    "    '''Cette fonction ouvre un fichier json et récupère une liste de toutes les clés d'un dictionnaire\n",
    "    Il retourne le fichier json dans une variable et la liste de toutes les clés'''\n",
    "\n",
    "    #Ouverture du fichier csv\n",
    "    with open(nom_fichier,\"r\") as jsonfil:\n",
    "        data_gare = json.load(jsonfil)\n",
    "    toutes_id = data_gare[\"id\"]\n",
    "    liste_cles = []\n",
    "    # J'ajoute toutes les clés du dictionnaire id dans une liste\n",
    "    [liste_cles.append(cle) for cle in toutes_id.keys()]\n",
    "    return data_gare,liste_cles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arrivee:\n",
    "    arrivee_id:                         str\n",
    "    gare_id:                            str | None\n",
    "    departure_date_time:                datetime.datetime | None\n",
    "    base_departure_date_time:           datetime.datetime | None\n",
    "    arrival_date_time:                  datetime.datetime | None\n",
    "    base_arrival_date_time:             datetime.datetime | None\n",
    "    network:                            str | None\n",
    "    ligne:                              str | None\n",
    "    trip:                               str | None\n",
    "    direction:                          str | None\n",
    "    disruption_id:                      str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Perturbation:\n",
    "    perturbation_id:                        str | None\n",
    "    debut:                                  datetime.datetime | None\n",
    "    fin:                                    datetime.datetime | None\n",
    "    effet:                                  str | None\n",
    "    message:                                str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraire_donnees(data,liste_cles:list):\n",
    "    '''Cette fonction permet d'extraire une donnée dans un dictionnaire'''\n",
    "    try:\n",
    "        for cle in liste_cles:\n",
    "            #Cas ou la donnée est stockée dans un dictionnaire\n",
    "            if type(data) is dict:\n",
    "                data = data[cle]\n",
    "            #Cas ou la données est stockée dans une liste, alors on prend le premier element de la liste\n",
    "            else:\n",
    "                data=data[0][cle]\n",
    "        return data\n",
    "    except (KeyError,IndexError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collecte_donnees_arrivee(json_arrivee):\n",
    "    '''Cette fonction instancie une arrivée et remplie les champs en extrayant les données d'un dictionnaire'''\n",
    "    arrivee = Arrivee(\n",
    "        arrivee_id = extraire_donnees(json_arrivee,[\"stop_point\",\"stop_area\",\"id\"]).split(\":\")[-1]+\"-\" \\\n",
    "            + convertir_en_datetime(extraire_donnees(json_arrivee,[\"stop_date_time\",\"arrival_date_time\"])).strftime(\"%Y%m%d\") + \"-\"\\\n",
    "            + extraire_donnees(json_arrivee,[\"display_informations\",\"trip_short_name\"]),\n",
    "        gare_id = extraire_donnees(json_arrivee,[\"stop_point\",\"stop_area\",\"id\"]),\n",
    "        departure_date_time = convertir_en_datetime(extraire_donnees(json_arrivee,[\"stop_date_time\",\"departure_date_time\"])),\n",
    "        base_departure_date_time = convertir_en_datetime(extraire_donnees(json_arrivee,[\"stop_date_time\",\"base_departure_date_time\"])),\n",
    "        arrival_date_time = convertir_en_datetime(extraire_donnees(json_arrivee,[\"stop_date_time\",\"arrival_date_time\"])),\n",
    "        base_arrival_date_time = convertir_en_datetime(extraire_donnees(json_arrivee,[\"stop_date_time\",\"base_arrival_date_time\"])),\n",
    "        network = extraire_donnees(json_arrivee,[\"display_informations\",\"network\"]),\n",
    "        ligne = extraire_donnees(json_arrivee,[\"display_informations\",\"label\"]),\n",
    "        trip = extraire_donnees(json_arrivee,[\"display_informations\",\"trip_short_name\"]),\n",
    "        direction = extraire_donnees(json_arrivee,[\"display_informations\",\"direction\"]),\n",
    "        disruption_id = extraire_donnees(json_arrivee,[\"display_informations\",\"links\",\"id\"])\n",
    "    )\n",
    "    return asdict(arrivee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collecte_donnees_perturbation(json_perturbation):\n",
    "    '''Cette fonction instancie une perturbation et remplie les champs en extrayant les données d'un dictionnaire'''\n",
    "    perturbation = Perturbation(\n",
    "        perturbation_id = extraire_donnees(json_perturbation,[\"id\"]),\n",
    "        debut = extraire_donnees(json_perturbation,[\"application_periods\",\"begin\"]),\n",
    "        fin = extraire_donnees(json_perturbation,[\"application_periods\",\"end\"]),\n",
    "        effet = extraire_donnees(json_perturbation,[\"severity\",\"effect\"]),\n",
    "        message = extraire_donnees(json_perturbation,[\"messages\",\"text\"])\n",
    "    )\n",
    "    return asdict(perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stockage_en_bdd(nom_fichier):\n",
    "    '''Cette fonction place des données dans un dataframe et stocke le dataframe dans une base de donnée'''\n",
    "\n",
    "    #Chargement des données\n",
    "    df = pd.read_csv(nom_fichier)\n",
    "\n",
    "\n",
    "    #Schema de la table avec formatage\n",
    "    df_schema = {\n",
    "        \"arrivee_id\": String(255),\n",
    "        \"gare_id\": String(255),\n",
    "        \"departure_date_time\": DateTime,\n",
    "        \"base_departure_date_time\": DateTime,\n",
    "        \"arrival_date_time\": DateTime,\n",
    "        \"base_arrival_date_time\": DateTime,\n",
    "        \"network\": String(255),\n",
    "        \"ligne\": String(255),\n",
    "        \"trip\": String(255),\n",
    "        \"direction\": String(255),\n",
    "        \"disruption_id\": String(255)}\n",
    "\n",
    "    #Connexion à la base de données\n",
    "    con_string = f\"mysql+pymysql://root:{db_password}@localhost:{DB_PORT}/APP_SNCF\"\n",
    "    engine = create_engine(con_string,echo=False)\n",
    "    \n",
    "    try:\n",
    "        #Ajout des données à la base de donnée\n",
    "        with engine.connect() as con:\n",
    "            df.to_sql(\"arrivees\",con,if_exists=\"append\",index=False, dtype=df_schema)\n",
    "    except:\n",
    "        con.rollback()\n",
    "        print(\"Fait un petit rollback\")\n",
    "        raise\n",
    "\n",
    "    print(f\"Enregistrement dans la BDD de {len(df.axes[0])} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_gare,cle,date_min,date_max):\n",
    "    '''Cette fontion lance les fonctions pour traiter les données d'une gare'''\n",
    "    code_gare = data_gare[\"id\"].get(cle)\n",
    "    nom_gare = data_gare[\"nom\"].get(cle)\n",
    "    print(f\"Debut des requetes pour la gare: {nom_gare}\")\n",
    "\n",
    "    compteur_requete = 0\n",
    "    liste_code_reseau = []\n",
    "    liste_arrivees = []\n",
    "    liste_perturbations = []\n",
    "\n",
    "    #Récupération des identifiant réseaux pour la gare en cours\n",
    "    [liste_code_reseau.append(reseau[\"id\"]) for reseau in data_gare[\"networks\"].get(cle)]\n",
    "\n",
    "    # Je traite réseau par réseau\n",
    "    for reseau in liste_code_reseau:\n",
    "        liste_arrivees, liste_perturbations,compteur_requete = requete_entre_dates(code_gare,reseau,date_min,date_max,liste_arrivees,liste_perturbations,compteur_requete)\n",
    "\n",
    "    #Sauvegarde données brutes\n",
    "    nom_fichier_arrivees = f\"data/arrivees/{code_gare}-{date_max}.json\".replace(\":\",\"_\")\n",
    "    nom_fichier_perturbations = f\"data/perturbations/{code_gare}-{date_max}.json\".replace(\":\",\"_\")\n",
    "    to_json(liste_arrivees,nom_fichier_arrivees)\n",
    "    to_json(liste_perturbations,nom_fichier_perturbations)\n",
    "    \n",
    "    #Nettoyage des données\n",
    "    liste_arrivees_clean=[]\n",
    "    for arrivee in liste_arrivees:\n",
    "        data_clean_arrivees = collecte_donnees_arrivee(arrivee)\n",
    "        liste_arrivees_clean.append(data_clean_arrivees)    \n",
    "    liste_perturbations_clean=[]\n",
    "    for perturbation in liste_perturbations:\n",
    "        data_clean_perturbation =collecte_donnees_perturbation(perturbation)\n",
    "        liste_perturbations_clean.append(data_clean_perturbation)\n",
    "        \n",
    "    \n",
    "    print(f\"Fin des requetes pour la gare :{nom_gare} \\n {compteur_requete} requetes effectuées\")\n",
    "    \n",
    "    #Sauvegarde des données propres\n",
    "    nom_ficher_arrivees_clean = f\"data/arrivees_propres/{code_gare}-{date_max}.csv\".replace(\":\",\"_\")\n",
    "    nom_ficher_perturbations_clean = f\"data/perturbations_propres/{code_gare}-{date_max}.csv\".replace(\":\",\"_\")\n",
    "    #Vérifie si les listes contiennent des données\n",
    "    if liste_arrivees_clean:\n",
    "        to_csv(liste_arrivees_clean,nom_ficher_arrivees_clean)\n",
    "    if liste_perturbations_clean:\n",
    "        to_csv(liste_perturbations_clean,nom_ficher_perturbations_clean)\n",
    "    #Enregistrement en BDD\n",
    "    stockage_en_bdd(nom_ficher_arrivees_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de la clé API\n",
    "load_dotenv()\n",
    "api_key = os.getenv(CLEF_API)\n",
    "db_password = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation des string date permettant de faire les requete API \n",
    "aujourdhui = datetime.date.today()\n",
    "hier_debut_journee = datetime.datetime(year=aujourdhui.year, month=aujourdhui.month, day=aujourdhui.day-1, hour=0, minute=0 ,second=0)\n",
    "hier_fin_journee = datetime.datetime(year=aujourdhui.year, month=aujourdhui.month, day=aujourdhui.day-1, hour=23, minute=59 ,second=59)\n",
    "date_min = convertir_en_string(hier_debut_journee)\n",
    "date_max = convertir_en_string(hier_fin_journee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debut des requetes pour la gare: Paris Nord\n",
      "Fin des requetes pour la gare :Paris Nord \n",
      " 67 requetes effectuées\n",
      "Enregistrement dans la BDD de 628 lignes\n",
      "Debut des requetes pour la gare: Paris Saint-Lazare\n",
      "Fin des requetes pour la gare :Paris Saint-Lazare \n",
      " 45 requetes effectuées\n",
      "Enregistrement dans la BDD de 438 lignes\n",
      "Debut des requetes pour la gare: Paris - Gare de Lyon - Hall 1 & 2\n",
      "Fin des requetes pour la gare :Paris - Gare de Lyon - Hall 1 & 2 \n",
      " 76 requetes effectuées\n",
      "Enregistrement dans la BDD de 699 lignes\n",
      "Debut des requetes pour la gare: Paris - Montparnasse - Hall 1 & 2\n",
      "Fin des requetes pour la gare :Paris - Montparnasse - Hall 1 & 2 \n",
      " 24 requetes effectuées\n",
      "Enregistrement dans la BDD de 212 lignes\n",
      "Debut des requetes pour la gare: Paris Est\n",
      "Fin des requetes pour la gare :Paris Est \n",
      " 23 requetes effectuées\n",
      "Enregistrement dans la BDD de 179 lignes\n",
      "Debut des requetes pour la gare: Lyon Part Dieu\n",
      "Fin des requetes pour la gare :Lyon Part Dieu \n",
      " 42 requetes effectuées\n",
      "Enregistrement dans la BDD de 342 lignes\n",
      "Debut des requetes pour la gare: La Défense\n",
      "Fin des requetes pour la gare :La Défense \n",
      " 17 requetes effectuées\n",
      "Enregistrement dans la BDD de 160 lignes\n",
      "Debut des requetes pour la gare: Juvisy\n",
      "Fin des requetes pour la gare :Juvisy \n",
      " 29 requetes effectuées\n",
      "Enregistrement dans la BDD de 258 lignes\n",
      "Debut des requetes pour la gare: Saint-Denis\n",
      "Fin des requetes pour la gare :Saint-Denis \n",
      " 31 requetes effectuées\n",
      "Enregistrement dans la BDD de 303 lignes\n",
      "Debut des requetes pour la gare: Bibliothèque François Mitterrand\n",
      "Fin des requetes pour la gare :Bibliothèque François Mitterrand \n",
      " 22 requetes effectuées\n",
      "Enregistrement dans la BDD de 217 lignes\n"
     ]
    }
   ],
   "source": [
    "# Récupération des clés dictionnaire contenant les informations des gares\n",
    "data_gare,liste_cle = liste_id(\"data/top200gare.json\")\n",
    "# Exécution du run pour chaque gare\n",
    "for cle in liste_cle[:10]:\n",
    "    run(data_gare,cle,date_min,date_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
